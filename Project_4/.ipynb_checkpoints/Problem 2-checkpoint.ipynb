{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b62f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "X = data.drop(columns='Outcome')  \n",
    "y = data['Outcome']\n",
    "\n",
    "# Standardizing all the predictors\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebad1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error Rate (Logistic Regression): 0.2240\n"
     ]
    }
   ],
   "source": [
    "#LOOCV set up\n",
    "loo = LeaveOneOut()\n",
    "errors = []\n",
    "\n",
    "# Logistic Regression with LOOCV\n",
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    \n",
    "    #determining values for each one per index \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # here we are creating the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting data and also finding error\n",
    "    y_pred = model.predict(X_test)\n",
    "    #using 1 if not successufl and 0 if it is\n",
    "    errors.append(1 if y_pred[0] != y_test.iloc[0] else 0)  # Comparing the outcome values\n",
    "\n",
    "# Test error rate by averaging all the values\n",
    "test_error_logistic = np.mean(errors)\n",
    "print(f\"Test Error Rate (Logistic Regression): {test_error_logistic:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c82b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Penalty (Ridge): 35.5648\n",
      "Test Error Rate (Ridge Regression): 0.2240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hasan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:2341: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "# alphas represent penaties for ridge classifiers\n",
    "alphas = np.logspace(-4, 4, 50)\n",
    "\n",
    "# setting up ridge model with alphas and fitting it with the scaled data\n",
    "ridge_model = RidgeClassifierCV(alphas=alphas, store_cv_values=True) #ridge classifier CV as our LOOCV\n",
    "ridge_model.fit(X_scaled, y)\n",
    "\n",
    "#here we are finding OPTIMAL alpha for ridge classifer\n",
    "optimal_pen = ridge_model.alpha_ #finds our 'best' penalty\n",
    "test_error_ridge = 1 - ridge_model.score(X_scaled, y) # 1 - the accuracy for the error\n",
    "\n",
    "\n",
    "print(f\"Optimal Penalty : {optimal_pen:.4f}\")\n",
    "print(f\"Test Error Rate : {test_error_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e70d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Penalty (Lasso): 0.3907\n",
      "Test Error Rate (Lasso Regression): 0.2227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define penalty range for Lasso (L1)\n",
    "param_grid = {'C': np.logspace(-4, 4, 50)}  \n",
    "\n",
    "#model set up\n",
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "# Use LOOCV to choose the best penalty parameter\n",
    "grid = GridSearchCV(lasso_model, param_grid, cv=loo, scoring='accuracy') #specified LOOCV\n",
    "grid.fit(X_scaled, y) #fitting the grid with values\n",
    "\n",
    "#determining optimal pen and the error\n",
    "optimal_pen_lasso = grid.best_params_['C']\n",
    "test_error_lasso = 1 - grid.best_score_\n",
    "\n",
    "print(f\"Optimal Penalty: {optimal_pen_lasso:.4f}\")\n",
    "print(f\"Test Error Rate : {test_error_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d69463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Optimal Penalty</th>\n",
       "      <th>Test Error Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>35.564803</td>\n",
       "      <td>0.223958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.390694</td>\n",
       "      <td>0.222656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Optimal Penalty  Test Error Rate\n",
       "0  Logistic Regression              NaN         0.223958\n",
       "1     Ridge Regression        35.564803         0.223958\n",
       "2     Lasso Regression         0.390694         0.222656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Ridge Regression\", \"Lasso Regression\"],\n",
    "    \"Optimal Penalty\": [None, optimal_alpha_ridge, optimal_alpha_lasso], # no pen for Log Reg\n",
    "    \"Test Error Rate\": [test_error_logistic, test_error_ridge, test_error_lasso]\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131d804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
